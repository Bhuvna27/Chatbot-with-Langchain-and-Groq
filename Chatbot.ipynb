{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386ae75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8341c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ee95b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x109e4b350>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x109f8a950>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a57c8a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Bhuvana, it's nice to meet you!\\n\\nBeing an AI Engineer is a fascinating field. What kind of projects are you working on?  \\n\\nI'm always eager to learn more about what people are doing in the world of AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 22, 'total_tokens': 77, 'completion_time': 0.1, 'prompt_time': 0.00134945, 'queue_time': 0.088281384, 'total_time': 0.10134945}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5568ab46-5dc6-44ce-9243-1110cf1488eb-0', usage_metadata={'input_tokens': 22, 'output_tokens': 55, 'total_tokens': 77})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My name is Bhuvana and I am an AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506e0e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Krish and that you are a Chief AI Engineer.  üòÑ \\n\\nIs there anything else you'd like to tell me about yourself or your work?  I'm happy to chat! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 97, 'total_tokens': 146, 'completion_time': 0.089090909, 'prompt_time': 0.0028052, 'queue_time': 0.088390037, 'total_time': 0.091896109}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b8afdb5-ba68-45eb-a515-b7df41ff1ba3-0', usage_metadata={'input_tokens': 97, 'output_tokens': 49, 'total_tokens': 146})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Krish and I am a Chief AI Engineer\"),\n",
    "        AIMessage(content=\"Hello Krish! It's nice to meet you. \\n\\nAs a Chief AI Engineer, what kind of projects are you working on these days? \\n\\nI'm always eager to learn more about the exciting work being done in the field of AI.\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed447ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8209c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"1234\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe7d664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Bhuvana! It's nice to meet you. \\n\\nThat's a fascinating field! What kind of AI projects are you working on these days?  \\n\\nI'm always eager to learn more about the work that AI engineers are doing.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 22, 'total_tokens': 77, 'completion_time': 0.1, 'prompt_time': 0.001329001, 'queue_time': 0.089398243, 'total_time': 0.101329001}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--79ac021a-0910-4868-a0bc-18ffee162066-0', usage_metadata={'input_tokens': 22, 'output_tokens': 55, 'total_tokens': 77})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [ HumanMessage(content=\"Hi , My name is Bhuvana and I am an AI Engineer\")],config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e889759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Bhuvana, and you are an AI Engineer!  \\n\\nIs there anything else you'd like to tell me about yourself or your work? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 97, 'total_tokens': 133, 'completion_time': 0.065454545, 'prompt_time': 0.00266458, 'queue_time': 0.089340684, 'total_time': 0.068119125}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--42f9da25-d555-406d-aeb5-6a2f17d6b5ca-0', usage_metadata={'input_tokens': 97, 'output_tokens': 36, 'total_tokens': 133})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [ HumanMessage(content = \"Hey What's my name and what do I do?\")],config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa4194a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My previous response was:\\n\\n\"Hello Bhuvana! It\\'s nice to meet you.  \\n\\nThat\\'s a fascinating field! What kind of AI projects are you working on these days?  \\n\\nI\\'m always eager to learn more about the work that AI engineers are doing.\"\\n\\n\\nI also stated that you are Bhuvana, and you are an AI Engineer.  Is there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 149, 'total_tokens': 239, 'completion_time': 0.163636364, 'prompt_time': 0.00407558, 'queue_time': 0.08832426800000001, 'total_time': 0.167711944}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--70c22ac9-6265-4a6f-a50f-debbcd07eeac-0', usage_metadata={'input_tokens': 149, 'output_tokens': 90, 'total_tokens': 239})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [ HumanMessage(content = \"Hey, what was your previous response?\")],config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e75a98",
   "metadata": {},
   "source": [
    "# Prompt Templates - It allows you to pass user inputs in an expected way to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d8d32",
   "metadata": {},
   "source": [
    "### Step - 1: Create the Prompt Template\n",
    "### Step - 2: Create a chain with model and above prompt template\n",
    "### Step - 3: Make the model stateful with a RunnableMessageHistory Class\n",
    "### Step - 4: Invoke the stateful model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337cc2cf",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71139a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Amnswer all the question to the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ead2094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Bhuvana! It's nice to meet you. \\n\\nI'm happy to answer any questions you have to the best of my ability. As an AI, I can access and process information from the real world through Google Search and keep my response consistent with search results.  \\n\\nWhat can I help you with today? üòä \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 38, 'total_tokens': 111, 'completion_time': 0.132727273, 'prompt_time': 0.00156064, 'queue_time': 0.089474016, 'total_time': 0.134287913}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a8810b34-0372-4196-9e1e-3ea5e2a3b9cf-0', usage_metadata={'input_tokens': 38, 'output_tokens': 73, 'total_tokens': 111})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Bhuvana and I am an AI Engineer\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76083c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca5e037",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mchat3\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m response = \u001b[43mwith_message_history\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHi My name is Bhuvana and I am an AI Engineer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlanguage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHindi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/base.py:5434\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5427\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5429\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5432\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5433\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/base.py:5434\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5427\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5429\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5432\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5433\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/base.py:3044\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3042\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3043\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3044\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3045\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3046\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/base.py:5434\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5427\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5429\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5432\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5433\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/base.py:4775\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4761\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[32m   4762\u001b[39m \n\u001b[32m   4763\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4772\u001b[39m \u001b[33;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[32m   4773\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4776\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4777\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4778\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4779\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4780\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4781\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4782\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/base.py:1939\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1935\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1936\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1937\u001b[39m         output = cast(\n\u001b[32m   1938\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1939\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1940\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1947\u001b[39m         )\n\u001b[32m   1948\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1949\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/base.py:4633\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4631\u001b[39m                 output = chunk\n\u001b[32m   4632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4633\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4634\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4635\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4636\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/history.py:525\u001b[39m, in \u001b[36mRunnableWithMessageHistory._enter_history\u001b[39m\u001b[34m(self, value, config)\u001b[39m\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.history_messages_key:\n\u001b[32m    521\u001b[39m     \u001b[38;5;66;03m# return all messages\u001b[39;00m\n\u001b[32m    522\u001b[39m     input_val = (\n\u001b[32m    523\u001b[39m         value \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_messages_key \u001b[38;5;28;01melse\u001b[39;00m value[\u001b[38;5;28mself\u001b[39m.input_messages_key]\n\u001b[32m    524\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     messages += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_input_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m messages\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/genai/lib/python3.11/site-packages/langchain_core/runnables/history.py:452\u001b[39m, in \u001b[36mRunnableWithMessageHistory._get_input_messages\u001b[39m\u001b[34m(self, input_val)\u001b[39m\n\u001b[32m    450\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    451\u001b[39m         key = \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     input_val = \u001b[43minput_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# If value is a string, convert to a human message\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_val, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[31mKeyError\u001b[39m: 'input'"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi My name is Bhuvana and I am an AI Engineer\")],\"language\": \"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50106367",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7bc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§≠‡•Å‡§µ‡§®‡§æ! üòä  ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§  ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•Å‡§õ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Bhuvana\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3804f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§≠‡•Å‡§µ‡•Ä! üòä  \\n\\n‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? \\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi,I am Bhuvi\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9614b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my Bhuvi?\")], \"language\": \"Hindi\"},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d56fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§≠‡•Å‡§µ‡•Ä ‡§π‡•à‡•§ üòä  \\n\\n‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§î‡§∞ ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? \\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615aac26",
   "metadata": {},
   "source": [
    "### Limiting the context of the conversation or information by trim_messages method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232bf432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05040028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/genai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ba10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to your personal information, including your ice cream preferences!  \\n\\nWhat's your favorite flavor? üòä\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9afba31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked: \"What\\'s 2 + 2?\"\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf71469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f612701",
   "metadata": {},
   "source": [
    "# Documents\n",
    "LangChain implements a Document abstraction, which is intended to represent a unit of text and associated metadata. It has two attributes:\n",
    "\n",
    "- page_content: a string representing the content;\n",
    "- metadata: a dict containing arbitrary metadata.\n",
    "The metadata attribute can capture information about the source of the document, its relationship to other documents, and other information. Note that an individual Document object often represents a chunk of a larger document.\n",
    "\n",
    "Let's generate some sample documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain) (0.3.69)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain) (0.4.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-core>=0.3.60 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-chroma) (0.3.69)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-chroma) (2.3.1)\n",
      "Requirement already satisfied: chromadb>=1.0.9 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-chroma) (1.0.15)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.4.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (4.14.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.34.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (0.21.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (1.73.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from chromadb>=1.0.9->langchain-chroma) (4.24.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2025.6.15)\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma) (1.2.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.26.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.6.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core>=0.3.60->langchain-chroma) (0.4.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core>=0.3.60->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.60->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain-chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain-chroma) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain-chroma) (0.4.1)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (5.29.5)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma) (0.55b1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (0.33.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (1.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
      "Downloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: langchain-chroma\n",
      "Successfully installed langchain-chroma-0.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_groq in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (0.3.6)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain_groq) (0.3.69)\n",
      "Requirement already satisfied: groq<1,>=0.29.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain_groq) (0.30.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from groq<1,>=0.29.0->langchain_groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from groq<1,>=0.29.0->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from groq<1,>=0.29.0->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from groq<1,>=0.29.0->langchain_groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from groq<1,>=0.29.0->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from groq<1,>=0.29.0->langchain_groq) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.29.0->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (0.4.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/genai/lib/python3.11/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-chroma\n",
    "!pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
    "        metadata={\"source\": \"fish-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
    "        metadata={\"source\": \"bird-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7794204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x135fe5890>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x132b63e10>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model=\"Llama3-8b-8192\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abd2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x13d3e0d10>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VectorStores\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vectorstore=Chroma.from_documents(documents,embedding=embeddings)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a089d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='60a9df8c-cc9d-470f-9d1c-4fea2c61cee9', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
       " Document(id='439505e7-6adf-401b-a2b7-ffb68e529be0', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
       " Document(id='1c7a0a32-65e9-4696-8ff5-4337adbf410c', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
       " Document(id='b3a577db-2354-4b06-80d3-bd5d475a043f', metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246b0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='60a9df8c-cc9d-470f-9d1c-4fea2c61cee9', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
       " Document(id='439505e7-6adf-401b-a2b7-ffb68e529be0', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
       " Document(id='1c7a0a32-65e9-4696-8ff5-4337adbf410c', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
       " Document(id='b3a577db-2354-4b06-80d3-bd5d475a043f', metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Async query\n",
    "await vectorstore.asimilarity_search(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f1820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='60a9df8c-cc9d-470f-9d1c-4fea2c61cee9', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
       "  0.9351058006286621),\n",
       " (Document(id='439505e7-6adf-401b-a2b7-ffb68e529be0', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
       "  1.574089765548706),\n",
       " (Document(id='1c7a0a32-65e9-4696-8ff5-4337adbf410c', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
       "  1.5956909656524658),\n",
       " (Document(id='b3a577db-2354-4b06-80d3-bd5d475a043f', metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'),\n",
       "  1.66579270362854)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c7e64",
   "metadata": {},
   "source": [
    "### Retrievers\n",
    "LangChain VectorStore objects do not subclass Runnable, and so cannot immediately be integrated into LangChain Expression Language chains.\n",
    "\n",
    "LangChain Retrievers are Runnables, so they implement a standard set of methods (e.g., synchronous and asynchronous invoke and batch operations) and are designed to be incorporated in LCEL chains.\n",
    "\n",
    "We can create a simple version of this ourselves, without subclassing Retriever. If we choose what method we wish to use to retrieve documents, we can create a runnable easily. Below we will build one around the similarity_search method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c7ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='60a9df8c-cc9d-470f-9d1c-4fea2c61cee9', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.')],\n",
       " [Document(id='439505e7-6adf-401b-a2b7-ffb68e529be0', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.')]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "retriever=RunnableLambda(vectorstore.similarity_search).bind(k=1)\n",
    "retriever.batch([\"cat\",\"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4426a4d",
   "metadata": {},
   "source": [
    "### Vectorstores implement an as_retriever method that will generate a Retriever, specifically a VectorStoreRetriever. These retrievers include specific search_type and search_kwargs attributes that identify what methods of the underlying vector store to call, and how to parameterize them. For instance, we can replicate the above with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b64e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='60a9df8c-cc9d-470f-9d1c-4fea2c61cee9', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.')],\n",
       " [Document(id='439505e7-6adf-401b-a2b7-ffb68e529be0', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.')]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":1}\n",
    ")\n",
    "retriever.batch([\"cat\",\"dog\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff112ae",
   "metadata": {},
   "source": [
    "# 1. LLM need's the question and the context to answer something\n",
    "# 2. Context exist in the retriever which act's as knowledge base\n",
    "# 3. RunnablePassthrough will forward the question untouched\n",
    "# 4. There is a clean separation of components as you can see using the composition or the pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf29644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, dogs are known for their loyalty and friendliness, making them great companions.\n"
     ]
    }
   ],
   "source": [
    "## RAG\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "message = \"\"\"\n",
    "Answer this question using the provided context only.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "\n",
    "rag_chain={\"context\":retriever,\"question\":RunnablePassthrough()}|prompt|llm\n",
    "\n",
    "response=rag_chain.invoke(\"tell me about dogs\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
